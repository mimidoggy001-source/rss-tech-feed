name: Update RSS Feeds

on:
  # æ¯å¤© 21:00ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰æ‰§è¡Œ
  schedule:
    - cron: "0 13 * * *"
  workflow_dispatch:

jobs:
  update:
    runs-on: ubuntu-latest

    steps:
    # -----------------------
    # 1) æ‹‰å–ä»“åº“
    # -----------------------
    - name: Checkout repo
      uses: actions/checkout@v3

    # -----------------------
    # 2) Python ç¯å¢ƒ
    # -----------------------
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name: Install dependencies
      run: |
        pip install feedparser requests googletrans==4.0.0-rc1

    # -----------------------
    # 3) æŠ“å– RSS
    # -----------------------
    - name: Fetch RSS & Generate feeds.json
      run: |
        python <<EOF
        import feedparser, json, requests, time

        rss_list = [
            ("TechCrunch", "https://techcrunch.com/feed/"),
            ("The Verge", "https://www.theverge.com/rss/index.xml"),
            ("Engadget", "https://www.engadget.com/rss.xml"),
            ("Wired", "https://www.wired.com/feed/rss"),
            ("Ars Technica", "https://feeds.arstechnica.com/arstechnica/index/"),
            ("Tom's Guide", "https://www.tomsguide.com/feeds/all"),
            ("Polygon", "https://www.polygon.com/rss/index.xml"),
            ("IGN", "https://www.ign.com/rss"),
            ("GameSpot", "https://www.gamespot.com/feeds/mashup/"),
            ("Bloomberg Tech", "https://feeds.bloomberg.com/technology/news.rss"),
            ("VentureBeat AI", "https://venturebeat.com/category/ai/feed/"),
            ("MIT Tech Review", "https://www.technologyreview.com/feed/")
        ]

        all_items = []

        for name, url in rss_list:
            try:
                feed = feedparser.parse(url)
                for e in feed.entries[:20]:
                    all_items.append({
                        "title": e.get("title", ""),
                        "url": e.get("link", ""),
                        "platform": name,
                        "summary": e.get("summary", "")[:300],
                        "published": e.get("published", "")
                    })
            except Exception as err:
                print("âŒ RSS è§£æé”™è¯¯:", name, url, err)

        with open("feeds.json", "w", encoding="utf-8") as f:
            json.dump(all_items, f, ensure_ascii=False, indent=2)

        print("âœ” RSS æŠ“å–å®Œæˆï¼Œå†™å…¥ feeds.jsonï¼Œå…±", len(all_items), "æ¡")
        EOF

    # -----------------------
    # 4) æ¨é€åˆ°é’‰é’‰
    # -----------------------
    - name: Send digest to DingTalk
      env:
        DINGTALK_WEBHOOK: ${{ secrets.DINGTALK_WEBHOOK }}
      run: |
        python <<EOF
        import os, json, datetime, urllib.request
        from googletrans import Translator

        webhook = os.environ.get("DINGTALK_WEBHOOK")
        if not webhook or not webhook.startswith("http"):
            raise SystemExit("âŒ ERROR: DINGTALK_WEBHOOK æœªé…ç½®æˆ–æ ¼å¼é”™è¯¯")

        # è¯»å–æ•°æ®
        with open("feeds.json", "r", encoding="utf-8") as f:
            data = json.load(f)

        # çƒ­ç‚¹å…³é”®è¯ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
        hot_keywords = [
            "AI", "äººå·¥æ™ºèƒ½", "èŠ¯ç‰‡", "åŠå¯¼ä½“", "é‡å­", "è‡ªåŠ¨é©¾é©¶",
            "ç”Ÿæˆå¼", "OpenAI", "é©¬æ–¯å…‹", "ç‰¹æ–¯æ‹‰", "è‹¹æœ", "åä¸º",
            "Meta", "Google", "NVIDIA", "GPT", "Robot", "æ— äººæœº"
        ]

        def is_hot(title, summary):
            t = (title + " " + summary).lower()
            return any(kw.lower() in t for kw in hot_keywords)

        hot_items = [item for item in data if is_hot(item["title"], item["summary"])]

        # æ²¡æœ‰çƒ­ç‚¹åˆ™ fallback
        items = hot_items[:15] if hot_items else data[:15]

        translator = Translator()

        def to_zh(text):
            try:
                return translator.translate(text, dest="zh-cn").text
            except:
                return text  # å¤±è´¥æ—¶ä¿ç•™è‹±æ–‡

        now = datetime.datetime.utcnow() + datetime.timedelta(hours=8)
        ts = now.strftime("%Y-%m-%d %H:%M")

        lines = []
        lines.append(f"### ğŸŒ çƒ­ç‚¹ç§‘æŠ€åª’ä½“æ—¥æŠ¥ï¼ˆ{ts}ï¼‰\\n")

        if hot_items:
            lines.append(f"å…±æŠ“å– {len(data)} æ¡ï¼Œå…¶ä¸­çƒ­ç‚¹ {len(hot_items)} æ¡\\n\\n")
        else:
            lines.append(f"å…±æŠ“å– {len(data)} æ¡ï¼ˆæ— çƒ­ç‚¹ï¼Œå±•ç¤ºæœ€æ–° 15 æ¡ï¼‰\\n\\n")

        for i, item in enumerate(items, 1):
            title_cn = to_zh(item["title"])
            lines.append(f"**{i}. [{item['platform']}] {title_cn}**\\n")
            lines.append(f"{item['url']}\\n\\n")

        text = "".join(lines)

        payload = {
            "msgtype": "markdown",
            "markdown": {"title": "çƒ­ç‚¹ç§‘æŠ€åª’ä½“æ—¥æŠ¥", "text": text}
        }

        req = urllib.request.Request(
            webhook,
            data=json.dumps(payload).encode(),
            headers={"Content-Type": "application/json"}
        )
        with urllib.request.urlopen(req) as resp:
            print("é’‰é’‰å“åº”:", resp.read().decode())
        EOF

    # -----------------------
    # 5) è‡ªåŠ¨æäº¤
    # -----------------------
    - name: Commit updates
      run: |
        git config --global user.email "actions@github.com"
        git config --global user.name "GitHub Actions"
        git add feeds.json
        git commit -m "Update RSS feeds" || echo "No changes"
        git push
